{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**requests** Docs](https://requests.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "[**BeautifulSoup** Docs](https://beautiful-soup-4.readthedocs.io/en/latest/)\n",
    "\n",
    "[**wget** Docs](https://pypi.org/project/wget/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <center><a id=1>Парсинг сайта</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Поиск ссылки`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE68849&format=file'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "\n",
    "site_url = 'https://www.ncbi.nlm.nih.gov'  # Url сайта\n",
    "datasets_url = '/geo/query/acc.cgi'        # Url поиска датасетов\n",
    "parameter = 'GSE68849'                     # Название датасета\n",
    "\n",
    "response = requests.get(site_url + datasets_url, params={'acc' : parameter})  # GET-запрос к поиску конкретного датасета\n",
    "page = BeautifulSoup(response.text, 'html.parser')                            # Считывание html-информации\n",
    "\n",
    "attribute = 'acc=' + parameter                                                # Атрибут по которому фильтруются ссылки\n",
    "\n",
    "links = page.find_all(name='a', href=[ re.compile(attribute)])                # Поиск списка ссылок с параметром - название датасета\n",
    "\n",
    "for link in links:\n",
    "    search_link = re.compile(r'format=file$').search(link.get('href'))        # Поиск ссылки из списка с форматом только файл\n",
    "    if search_link is not None:\n",
    "        result_search = link\n",
    "result_search = result_search.get('href')                                     # Извлечение текста относительной ссылки\n",
    "download_link = site_url + result_search                                      # Получение ссылки для скачивания датасета\n",
    "download_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Создание папки`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    os.mkdir('data')\n",
    "except FileExistsError:\n",
    "    print('_'*31, \"\\nThis directory already exists !\\n\",'_'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Скачивание файла`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data//GSE68849_RAW.tar'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "\n",
    "wget.download(download_link, out='data/')  #  Без \"/\" назначается новое название файла"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <center><a id=2>Распаковка архива</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**os** Docs](https://docs.python.org/3/library/os.html)\n",
    "\n",
    "[**tarfile** Docs](https://docs.python.org/3/library/tarfile.html#module-tarfile)\n",
    "| [**tarfile** About](https://docs-python.ru/standart-library/modul-tarfile-python/metody-obekta-tarfile-modulja-tarfile/#tarfile.TarFile.open)\n",
    "\n",
    "[**gzip** Docs](https://docs.python.org/3/library/gzip.html#module-gzip)\n",
    "| [**gzip** About](https://docs-python.ru/standart-library/modul-gzip-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "def extract_file(filedir_path:str) -> int:\n",
    "    \n",
    "    \"\"\"Распаковывает архив в текущей папке\n",
    "\n",
    "    Args:\n",
    "        filedir_path (str): Путь к папке с архивом\n",
    "\n",
    "    Returns:\n",
    "        int: Если архив распакован, возвращает 1, если не распакован - 0\n",
    "    \"\"\"\n",
    "    os.chdir(filedir_path)\n",
    "    extracted_flag = 0\n",
    "    filenames_list = list(os.walk(filedir_path))[0][2]\n",
    "    for filename in filenames_list:\n",
    "        filename_short = os.path.splitext(filename)[0]\n",
    "        file_extension = os.path.splitext(filename)[1]\n",
    "        \n",
    "        if file_extension in ['.tar', '.gzip', '.bz2', '.lzma'] :    \n",
    "            with tarfile.open(filename) as tar:\n",
    "                tar.extractall()\n",
    "            extracted_flag = 1\n",
    "            os.remove(filename)\n",
    "                \n",
    "        if file_extension in ['.gz'] :\n",
    "            with gzip.open(filename, 'rb') as file_in:\n",
    "                with open(filename_short, 'wb') as file_out:\n",
    "                    shutil.copyfileobj(file_in, file_out)\n",
    "            extracted_flag = 1\n",
    "            os.remove(filename)\n",
    "    return extracted_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filedir_path = 'd:\\\\Learning\\\\Yandex Disk Sync\\\\YandexDisk\\\\MIPT.Data Science\\\\Инжиниринг данных\\\\Luigi\\\\Luigi Practice\\\\data'\n",
    "\n",
    "extracted_flag = 1\n",
    "while extracted_flag == 1:\n",
    "\n",
    "    extracted_flag = extract_file(filedir_path)\n",
    "    \n",
    "extracted_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <center><a id=3>Создание структуры</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def replace_files(filedir_path:str) -> None:\n",
    "    \"\"\"Перемещает файлы в созданные папки \n",
    "\n",
    "    Args:\n",
    "        filedir_path (str): Путь к папке с файлами для перемещения\n",
    "    \"\"\"\n",
    "    os.chdir(filedir_path)\n",
    "    filenames_list = list(os.walk(filedir_path))[0][2]\n",
    "    for filename in filenames_list:\n",
    "        filename_short = os.path.splitext(filename)[0]\n",
    "        try:\n",
    "            os.mkdir(filename_short)\n",
    "        except FileExistsError:\n",
    "            print('_'*31, \"\\nThis directory already exists !\\n\",'_'*30)\n",
    "        os.replace(filename, filename_short +'\\\\' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________ \n",
      "This directory already exists !\n",
      " ______________________________\n",
      "_______________________________ \n",
      "This directory already exists !\n",
      " ______________________________\n"
     ]
    }
   ],
   "source": [
    "filedir_path = 'd:\\\\Learning\\\\Yandex Disk Sync\\\\YandexDisk\\\\MIPT.Data Science\\\\Инжиниринг данных\\\\Luigi\\\\Luigi Practice\\\\data'\n",
    "replace_files(filedir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <center><a id=4>Экспорт  из csv в txt </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def export_to_csv(filename:str) -> None:\n",
    "    dfs = {}\n",
    "    with open(filename) as f:\n",
    "        write_key = None\n",
    "        fio = io.StringIO()\n",
    "        for l in f.readlines():\n",
    "            if l.startswith('['):\n",
    "                if write_key:\n",
    "                    fio.seek(0)\n",
    "                    header = None if write_key == 'Heading' else 'infer'\n",
    "                    dfs[write_key] = pd.read_csv(fio, sep='\\t', header=header)\n",
    "                fio = io.StringIO()\n",
    "                write_key = l.strip('[]\\n')\n",
    "                continue\n",
    "            if write_key:\n",
    "                fio.write(l)\n",
    "        fio.seek(0)\n",
    "        dfs[write_key] = pd.read_csv(fio, sep='\\t')\n",
    "    for df_name in dfs:\n",
    "        df = pd.DataFrame(dfs[df_name])\n",
    "        df.to_csv(f'{df_name}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filedir_path = 'd:\\\\Learning\\\\Yandex Disk Sync\\\\YandexDisk\\\\MIPT.Data Science\\\\Инжиниринг данных\\\\Luigi\\\\Luigi Practice\\\\data'\n",
    "\n",
    "def export_to_dir(filedir_path:str) -> None:\n",
    "    dirs_list = list(os.walk(filedir_path))[0][1]\n",
    "    for dir in dirs_list:\n",
    "        new_dir_path = filedir_path + '\\\\' + dir\n",
    "        os.chdir(new_dir_path)\n",
    "        filenames_list = list(os.walk(new_dir_path))[0][2]\n",
    "        for filename in filenames_list:\n",
    "            export_to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_dir(filedir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <center><a id=5>Редактирование файлов </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "filedir_path = os.getcwd()\n",
    "filename = 'Probes.csv'\n",
    "\n",
    "dirnames_list = list(os.walk(filedir_path))[0][1]\n",
    "\n",
    "for dirname in dirnames_list:\n",
    "    print(dirname)\n",
    "    \n",
    "    os.chdir(filedir_path + '\\\\' + dirname)\n",
    "    df = pd.read_csv(filename)\n",
    "    df_edited = df.drop(columns=['Definition', 'Ontology_Component', 'Ontology_Process', 'Ontology_Function', 'Synonyms', 'Obsolete_Probe_Id', 'Probe_Sequence'])\n",
    "    df_edited.to_csv('Probes_short.csv', index=False)\n",
    "    os.chdir(filedir_path)\n",
    "    print(df_edited.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
